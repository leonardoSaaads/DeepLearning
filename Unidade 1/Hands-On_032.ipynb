{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **HANDS-ON 3: Criando os Primeiros Neurônios (Parte 2)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vimos no [HANDS-ON 3: Criando os Primeiros Neurônios (Parte 01)](../Unidade%201/Hands-On_03.ipynb) que um modelo simples de neurônios pode ser feito com a seguite arquitetura:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.78  0.035 3.385]\n"
     ]
    }
   ],
   "source": [
    "#Importanto Bibliotecas\n",
    "import numpy as np\n",
    "\n",
    "# Definindo os valores de entrada\n",
    "inputs = [1.0, 2.0, 3.0, 2.5]\n",
    "\n",
    "# Definindo os pesos\n",
    "weights = [[0.12, 0.18, -0.15, 1.1],  \n",
    "           [0.15, -0.91, 0.26, -0.15],\n",
    "           [-0.26, -0.27, 0.17, 0.87]]\n",
    "\n",
    "# Definindo valores de bias (Constantes)\n",
    "biases = [1.0, 1.3, 1.5]\n",
    "\n",
    "# Computando os valores de saída\n",
    "layer_outputs = np.dot(weights, inputs) + biases\n",
    "\n",
    "# Printando resultados\n",
    "print(layer_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contudo, quando estamos criando e normalizando os valores para que uma determinada rede neural opere, os valores geralmente são passado em **lotes (batches, em inglês)**. Nos exemplos que trabalhos anteriormente, os valores dos inputs estavam sendo fornecidos um por vez (um Array Unidimensional), mas e se os valores fossem fornecidos como uma série de inputs de diversas observações (matriz numpy), ao invés de apenas uma observação por vez? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantos valores alocados: 3, e como estão alocados: (3,)\n",
      "Quantos valores alocados: 9, e como estão alocados: (3, 3)\n",
      "Quantos valores alocados: 18, e como estão alocados: (2, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Modelo de Array Unidimensional. (modelos que estávamos usando):\n",
    "array_1D = np.array([1, 2, 3])\n",
    "\n",
    "# Modelo de Array Bidimensional.\n",
    "array_2D = np.array([[1, 2, 3],\n",
    "                     [4, 5, 6],\n",
    "                     [7, 8, 9]])\n",
    "\n",
    "# Modelo de Array Tridimensional.\n",
    "array_3D = np.array([[[1, 2, 3],\n",
    "                     [4, 5, 6],\n",
    "                     [7, 8, 9]],\n",
    "                     [[10, 11, 12],\n",
    "                     [13, 14, 15],\n",
    "                     [16, 17, 18]]])\n",
    "\n",
    "# Dados do array Unidimensional\n",
    "print(f'Quantos valores alocados: {array_1D.size}, e como estão alocados: {array_1D.shape}')\n",
    "# Dados do array Bidimensional\n",
    "print(f'Quantos valores alocados: {array_2D.size}, e como estão alocados: {array_2D.shape}')\n",
    "# Dados do array Tridimensional\n",
    "print(f'Quantos valores alocados: {array_3D.size}, e como estão alocados: {array_3D.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É importante entendermos esses conceitos pois eles estão diretamente relacionados com os lotes que a rede neural irá receber. Comparando-se uma rede neural que recebe apenas um vetor unidimensional por vez e outra que recebe uma matriz dados por vez, é natural percebermos que a que recebe mais dados por vez tende a chegar ao equilibrio mais rapidamente. Em outras palavras, mais dados serão processados em paralelo, fazendo com que a rede consiga ter maior velocidade na hora do processamento. Uma observação importante a ser feita é que aumentar os valores dos lotes não implica em maior acurácia. Geralmente, o tempo de processamento diminui, mas, em compensação, a acurácia é afetada e pode diminuir.\n",
    "\n",
    "Como Kevin Shen expõe em seu artigo intitulado em inglês [\"Effect of batch size on training dynamics\"](https://medium.com/mini-distill/effect-of-batch-size-on-training-dynamics-21c14f7a716e) (Efeito dos lotes em treinamento dinâmico, em português):\n",
    "\n",
    "```{bibliography}\n",
    "O tamanho do lote é um dos hiperparâmetros mais importantes para ajustar os sistemas modernos de aprendizado profundo. Os praticantes geralmente desejam usar um tamanho de lote maior para treinar seu modelo, pois permite acelerações computacionais do paralelismo das GPUs. No entanto, é sabido que um tamanho de lote muito grande levará a uma generalização ruim (embora atualmente não se saiba por que isso acontece). [...]\n",
    "```\n",
    "\n",
    "Veja abaixo como pode ser o efeito dos lotes de entradas:\n",
    "\n",
    "# Necessário rever!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeira \"excitação\" do primeiro neurônio: -0.05, segunda -0.12, terceira -0.03 e quarta 0.39\n",
      "Primeira \"excitação\" do segundo neurônio: -0.16, segunda -0.4, terceira 0.09 e quarta -0.26\n",
      "Primeira \"excitação\" do terceiro neurônio: -0.31, segunda -0.28, terceira 0.21 e quarta -0.14\n",
      "Primeira \"excitação\" do quarto neurônio: 0.28, segunda -0.11, terceira -0.13 e quarta 0.4\n",
      "Primeira \"excitação\" do quinto neurônio: -0.48, segunda -0.02, terceira 0.25 e quarta 0.43\n",
      "Primeira \"excitação\" do sexto neurônio: -0.31, segunda -0.41, terceira 0.32 e quarta -0.38\n",
      "Primeira \"excitação\" do sétimo neurônio: -0.35, segunda -0.48, terceira -0.15 e quarta -0.09\n",
      "Primeira \"excitação\" do oitavo neurônio: 0.22, segunda 0.25, terceira 0.42 e quarta 0.15\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "batch = np.array([[-0.05, -0.12, -0.03, 0.39],   # Inputs do primeiro neurônio\n",
    "                  [-0.16, -0.4, 0.09, -0.26],    # Inputs do segundo neurônio\n",
    "                  [-0.31, -0.28, 0.21, -0.14],   # Inputs do terceiro neurônio\n",
    "                  [0.28, -0.11, -0.13, 0.4],     # Inputs do quarto neurônio\n",
    "                  [-0.48, -0.02, 0.25, 0.43],    # Inputs do quinto neurônio\n",
    "                  [-0.31, -0.41, 0.32, -0.38],   # Inputs do sexto neurônio\n",
    "                  [-0.35, -0.48, -0.15, -0.09],  # Inputs do sétimo neurônio\n",
    "                  [0.22, 0.25, 0.42, 0.15]])     # Inputs do oitavo neurônio\n",
    "\n",
    "print(f'Primeira \"excitação\" do primeiro neurônio: {batch[0][0]}, segunda {batch[0][1]}, terceira {batch[0][2]} e quarta {batch[0][3]}')\n",
    "print(f'Primeira \"excitação\" do segundo neurônio: {batch[1][0]}, segunda {batch[1][1]}, terceira {batch[1][2]} e quarta {batch[1][3]}')\n",
    "print(f'Primeira \"excitação\" do terceiro neurônio: {batch[2][0]}, segunda {batch[2][1]}, terceira {batch[2][2]} e quarta {batch[2][3]}')\n",
    "print(f'Primeira \"excitação\" do quarto neurônio: {batch[3][0]}, segunda {batch[3][1]}, terceira {batch[3][2]} e quarta {batch[3][3]}')\n",
    "print(f'Primeira \"excitação\" do quinto neurônio: {batch[4][0]}, segunda {batch[4][1]}, terceira {batch[4][2]} e quarta {batch[4][3]}')\n",
    "print(f'Primeira \"excitação\" do sexto neurônio: {batch[5][0]}, segunda {batch[5][1]}, terceira {batch[5][2]} e quarta {batch[5][3]}')\n",
    "print(f'Primeira \"excitação\" do sétimo neurônio: {batch[6][0]}, segunda {batch[6][1]}, terceira {batch[6][2]} e quarta {batch[6][3]}')\n",
    "print(f'Primeira \"excitação\" do oitavo neurônio: {batch[7][0]}, segunda {batch[7][1]}, terceira {batch[7][2]} e quarta {batch[7][3]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Referências Bibliográficas:**\n",
    "\n",
    "1 - **Effect of batch size on training dynamics, Kevin Shen**. Disponível em: <https://medium.com/mini-distill/effect-of-batch-size-on-training-dynamics-21c14f7a716e>. Acessado em 11 de maio de 2022\n",
    "\n",
    "4 - **Neural Nwtworks from Scratch in Python, Harrison Kinsley & Daniel Kukiela.**"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "83db9ccd60aaba7f36d82c7c8a804da99e0bc213c9e856efe6e157fa32ac376b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
