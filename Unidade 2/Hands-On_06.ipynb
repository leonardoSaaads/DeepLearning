{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Calculando Erro da Rede com Loss**\n",
    "\n",
    "Para que possamos criar, moldar e implementar uma rede neural, devemos ter parâmetros que serão utilizados como um guia nesse aprendizado. Um desses parêmtros é a função Loss (perda, em inglês), que também é chamada de Cost Function (função custo, em inglês). Essas funções permitem que o algoritmo quantifique o quão errado está o modelo em uma aplicação. naturalmente, é importante nortar que queremos uma função erro igual a zero, apesar disso ser praticamente impossível na prática."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Categorical Cross-Entropy Loss**\n",
    "\n",
    "O Categorical Cross-Entropy Loss é uma função utilizada para classificar multi classes. Quando estudávamos os problemas envolvendo regressões, utilizávamos o erro quadrático médio, contudo, quando os problemas passaram a ter um foco diferente, a abordagem para calcular o erro também teve de passar por modificações. \n",
    "\n",
    "Neste caso, faz sentido utilizar entropia cruzada, pois ela deriva de um ramo da teoria da informação onde, dada duas distribuições de probabilidade $p$ e $q$ sobre o mesmo conjunto subjacente de eventos, ela consegue medir o número médio de bits necessários para identificar um evento extraído do conjunto se um esquema de codificação usado para o conjunto for otimizado para um distribuição de probabilidade estimada $q$, em vez da distribuição verdadeira $p$. Em outras palavras, essa função compara uma probabilidade \"real\" com uma probabilidade \"prevista\". Como estamos lidando com probobilidades de classificação, esse método é muito usado em redes neurais onde a saida é dada por uma função Softmax. \n",
    "\n",
    "A fórmula para calcular a entropia cruzada categórica de $y$ (distribuição real/desejada) e\n",
    "$y'$ (distribuição prevista) é:\n",
    "\n",
    "$$L_{i} =  - \\sum_{j}y_{ij} \\log (y'_{ij})$$\n",
    "\n",
    "Onde $L$ é o valor Loss, $i$ é a i-ésima amostra no conjunto, $j$ é o índice de rótulo/saída.\n",
    "\n",
    "**Exemplo - 01**\n",
    "\n",
    "Calcule o erro do modelo usando Categorical Cross-Entropy para um vetor estimado igual $[0.45, 0.23, 0.7, 0.12]$ sabendo que o seu alvo é igual a $[0.4, 0.2, 0.5, 1]$.\n",
    "\n",
    "$$\\begin{align*}L_{i} &= - \\sum_{j}y_{ij} \\log (y'_{ij}) \\\\ \\, &= -(0.4\\log(0.45) + 0.2 \\log(0.23) + 0.5\\log(0.7) + 1\\log(0.12)) \\\\ \\, &= 2.91193928066835 \\end{align*}$$\n",
    "\n",
    "**Exemplo - 02**\n",
    "\n",
    "Sabendo-se que o valor estimado como output de uma rede neural com ativação Softmax é dado por $[0.7, 0.1, 0.2]$ e que o valor real é dado por $[1, 0, 0]$, calcule o erro com base na função Categorical Cross-Entropy.\n",
    "\n",
    "$$\\begin{align*}L_{i} &= - \\sum_{j}y_{ij} \\log (y'_{ij}) \\\\ \\, &= -(1\\log(0.7) + 0\\log(0.1) + 0\\log(0.2)) \\\\ \\, &= 0.35667494393873  \\end{align*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35667494393873245\n"
     ]
    }
   ],
   "source": [
    "# Exemplo em python 01:\n",
    "import numpy as np\n",
    "\n",
    "# O exemplo acima de categorical cross-Entropy - \"rótulo\" esperado pela rede neural\n",
    "softmax_output = [0.7, 0.1, 0.2]\n",
    "\n",
    "# \"rótulo\" verdadeiro\n",
    "target_output = [1, 0, 0]\n",
    "\n",
    "# Calcula o valor da função de custo\n",
    "loss = -(np.log(softmax_output[0])*target_output[0] +\n",
    "         np.log(softmax_output[1])*target_output[1] +\n",
    "         np.log(softmax_output[2])*target_output[2])\n",
    "\n",
    "# Printa o valor da função custo\n",
    "print(loss)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "83db9ccd60aaba7f36d82c7c8a804da99e0bc213c9e856efe6e157fa32ac376b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
